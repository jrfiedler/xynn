{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xynn.attntcn import AttnTCNClassifier\n",
    "from xynn.embedding import LinearEmbedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_num ─ Num. embedding ┐ ┌─ Attn ─ TCN ─ MLP ─┐\n",
      "                       ├─┤                    w+ ── output\n",
      "X_cat ─ Cat. embedding ┘ └──────── MLP ───────┘\n",
      "\n",
      "splits are copies and joins are concatenations;\n",
      "'w+' is weighted element-wise addition;\n",
      "\"Attn\" indicates 1 or more of AutoInt's AttentionInteractionLayer\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AttnTCNClassifier.diagram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 34589"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(root):\n",
    "    train_set = datasets.MNIST(root=root, train=True, download=True,\n",
    "                               transform=transforms.Compose([\n",
    "                                   transforms.ToTensor(),\n",
    "                                   transforms.Normalize((0.1307,), (0.3081,))\n",
    "                               ]))\n",
    "    test_set = datasets.MNIST(root=root, train=False, download=True,\n",
    "                              transform=transforms.Compose([\n",
    "                                  transforms.ToTensor(),\n",
    "                                  transforms.Normalize((0.1307,), (0.3081,))\n",
    "                              ]))\n",
    "\n",
    "    X_train, y_train = zip(*train_set)\n",
    "    X_valid, y_valid = zip(*test_set)\n",
    "    \n",
    "    y_train = torch.tensor(y_train)\n",
    "    y_valid = torch.tensor(y_valid)\n",
    "\n",
    "    X_num_train = torch.cat([x.flatten(start_dim=1) for x in X_train], dim=0)\n",
    "    X_num_valid = torch.cat([x.flatten(start_dim=1) for x in X_valid], dim=0)\n",
    "\n",
    "    X_cat_train = None\n",
    "    X_cat_valid = None\n",
    "\n",
    "    return (X_num_train, X_cat_train, y_train), (X_num_valid, X_cat_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, valid = data_generator(root=\"../data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num_train, X_cat_train, y_train = train\n",
    "X_num_valid, X_cat_valid, y_valid = valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_pred, y_true):\n",
    "    y_pred = torch.argmax(y_pred, dim=1)\n",
    "    acc = torch.eq(y_pred, y_true).to(dtype=torch.int).sum()\n",
    "    return 100 * acc / y_pred.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AttnTCNClassifier(\n",
    "    embedding_num=LinearEmbedding(1),\n",
    "    attn_embedding_size=5,\n",
    "    attn_num_layers=2,\n",
    "    tcn_output=\"non-temporal\",\n",
    "    tcn_hidden_sizes=[10] * 2,\n",
    "    tcn_kernel_size=3,\n",
    "    mlp_hidden_sizes=(512, 256, 128, 64),\n",
    "    seed=SEED,\n",
    "    #device=\"cuda\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  lrn rate  non-mlp  train loss   val loss   accuracy\n",
      "──────────────────────────────────────────────────────────\n",
      "    0    0.0100     0.43      0.1818     0.3980      87.12         \n",
      "    1    0.0100     0.42     0.09618     0.1440      95.74          \n",
      "    2    0.0100     0.41     0.06713     0.1030      96.84          \n",
      "    3    0.0100     0.40     0.06557    0.09986      96.94          \n",
      "    4    0.0100     0.40     0.04659     0.1146      96.78          \n"
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_num=X_num_train,\n",
    "    X_cat=X_cat_train,\n",
    "    y=y_train,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    opt_kwargs={\"lr\": 1e-2},\n",
    "    scheduler=torch.optim.lr_scheduler.StepLR,\n",
    "    sch_kwargs={\"step_size\": 5, \"gamma\": 0.1 ** 0.125},\n",
    "    val_sets=[[X_num_valid, X_cat_valid, y_valid]],\n",
    "    extra_metrics=[(\"accuracy\", accuracy)],\n",
    "    num_epochs=5,\n",
    "    batch_size=2048,\n",
    "    early_stopping_patience=10,\n",
    "    early_stopping_metric=\"accuracy\",\n",
    "    early_stopping_mode=\"max\",\n",
    "    warm_start=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
